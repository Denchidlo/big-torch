{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mnist import MNIST\n",
    "mndata = MNIST('./mnist')\n",
    "images, labels = mndata.load_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoded(y, num_class):\n",
    "    n = y.shape[0]\n",
    "    onehot = np.zeros((n, num_class), dtype=\"int32\")\n",
    "    for i in range(n):\n",
    "        idx = y[i]\n",
    "        onehot[i][idx] = 1\n",
    "    return onehot\n",
    "\n",
    "y = one_hot_encoded(y, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/denissimo/Repo/big-torch/src/big_torch/layers/loss.py:18: RuntimeWarning: divide by zero encountered in log\n",
      "  losses = - np.log(y_hat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - loss: inf\n",
      "Epoch 2 - loss: inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/denissimo/Repo/big-torch/src/big_torch/train/gradient_based.py:24: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  _eps = abs(prev_l0 - l0) if prev_l0 != None else 2*eps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 - loss: inf\n",
      "Epoch 4 - loss: inf\n",
      "Epoch 5 - loss: 6.619452520832119\n",
      "Epoch 6 - loss: 2.3371477051135523\n",
      "Epoch 7 - loss: 1.4497087951883665\n",
      "Epoch 8 - loss: 1.1473749086173486\n",
      "Epoch 9 - loss: 1.0400341013481738\n",
      "Epoch 10 - loss: 0.9653243966867039\n",
      "Epoch 11 - loss: 0.9069773434864231\n",
      "Epoch 12 - loss: 0.8585738992530099\n",
      "Epoch 13 - loss: 0.8171005162224404\n",
      "Epoch 14 - loss: 0.7808330670197916\n",
      "Epoch 15 - loss: 0.748572500974946\n",
      "Epoch 16 - loss: 0.7197194474531886\n",
      "Epoch 17 - loss: 0.6936988449078298\n",
      "Epoch 18 - loss: 0.6698881275864386\n",
      "Epoch 19 - loss: 0.6479860898816301\n",
      "Epoch 20 - loss: 0.6277704820215486\n",
      "Epoch 21 - loss: 0.6090394101630937\n",
      "Epoch 22 - loss: 0.5914857195288976\n",
      "Epoch 23 - loss: 0.5751077231324613\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_109668/574708213.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientDecent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.00005\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Repo/big-torch/src/big_torch/train/gradient_based.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, model, x_train, y_train, x_val, y_val, eta, eps, max_iter)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;32mwhile\u001b[0m  \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m             \u001b[0ml0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mask_oracul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m             \u001b[0mn_iter\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Epoch {n_iter} - loss: {l0}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Repo/big-torch/src/big_torch/models/model.py\u001b[0m in \u001b[0;36mask_oracul\u001b[0;34m(self, X, y, n_jobs, level)\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0mworker\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ModelInstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mworker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Repo/big-torch/src/big_torch/models/model.py\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(self, x, y, show_metrics)\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m     \u001b[0;32mclass\u001b[0m \u001b[0m_ModelParams\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Repo/big-torch/src/big_torch/models/model.py\u001b[0m in \u001b[0;36m_forward\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbprop_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbprop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fwd_prop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbprop_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbprop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Repo/big-torch/src/big_torch/layers/linear.py\u001b[0m in \u001b[0;36m_fwd_prop\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fwd_prop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_bckwd_prop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "net = models.Model()\n",
    "\n",
    "net.add_layer(layers.linear.LinearLayer((784, 100), b_initial=0, w_init='xavier_uniform'))\n",
    "net.add_layer(layers.activations.ReLU((100, 100)))\n",
    "net.add_layer(layers.linear.LinearLayer((100, 10) , b_initial=0, w_init='xavier_uniform'))\n",
    "net.add_layer(layers.activations.Softmax((10, 10)))\n",
    "net.set_loss(layers.loss.CrossEntropy((10, 1)))\n",
    "net.build()\n",
    "\n",
    "optimizer = train.GradientDecent()\n",
    "\n",
    "optimizer.train(net, x, y, eta=0.001, eps=0.00005, max_iter=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = 1233"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.80465887e-01, 5.15557310e-02, 8.24054754e-02, 1.15667174e-01,\n",
       "        1.57022690e-06, 5.55023067e-02, 5.10312281e-01, 4.01268420e-03,\n",
       "        7.01789126e-05, 6.71061631e-06]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.predict(np.array([x[obj]]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f5127137220>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x[obj].reshape((28,28)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 0, 0, 0, 0, 0, 0], dtype=int32)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[obj]"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f4b4b5902d9926e464429fdbfbd863f23dd70a9d7fce7d7862c6b9dc61b2b3d8"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('env': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
